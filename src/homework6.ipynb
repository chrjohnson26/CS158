{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2-_ZEnR0sjK"
   },
   "source": [
    "homework 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0428G5XVS0b"
   },
   "source": [
    "We begin by importing the regression versions of the models you learned about in previous assignments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fJUdREEf0gBc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "co7wHJpNVary"
   },
   "source": [
    "In this assignment, we will work with the California housing dataset. Read about it [here](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bWacTQz6NBTg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20640, 8), (20640,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqdzlF2dVwgs"
   },
   "source": [
    "As usual, we do a train/test split with 20% of our data set aside for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gZ_BA9xINWa2"
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_target, test_target = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2aSc26sV7HT"
   },
   "source": [
    "Define a function `mse` that returns the mean squared error between known values of the target (`y_true`) and predicted values (`y_pred`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "axFxRdwyNpIu"
   },
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return  1/(y_true.shape[0]) * np.sum((y_true-y_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6mW0UqoWTmv"
   },
   "source": [
    "Fit a Decision Tree Regressor to the training data. Use `random_state=42` and `max_depth=5`, so we all get the same answer. Then, use it to generate predictions for the test data and use your `mse` function to compute the mean squared error of those predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zFtdww-NNh5w"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5245146178314735"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree= DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "tree.fit(train_data, train_target) # Fitting the tree to the data and target\n",
    "predictions = tree.predict(test_data)\n",
    "tree_mse=mse(test_target,predictions)\n",
    "tree_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GycZ8BEEWzvO"
   },
   "source": [
    "Next, fit a Random Forest Regressor to the training data (use  `random_state=42`, `max_depth=5`, and `n_estimators=20`) and compute its mean squared error on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Z2LTDcL0OVQp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46673489271290713"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest= RandomForestRegressor(max_depth=5, random_state=42, n_estimators=20)\n",
    "forest.fit(train_data, train_target)\n",
    "predictions = forest.predict(test_data)\n",
    "forest_mse=mse(test_target,predictions)\n",
    "forest_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVKOx3VJXIwi"
   },
   "source": [
    "The main purpose of this assignment is to code up a Gradient Boosted Tree regression model class. Such a model trains a sequence of decision trees, where each one predicts the error (residuals) of the sum of all previous trees (with a learning rate applied to each for stability). Setting `n_estimators=1` would  produce a single decision tree, identical to the one produced by the `DecisionTreeRegressor` class.\n",
    "\n",
    "**Note:** Use `random_state=42` every time you initialize a Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resi = []                                 # Array to keep track of residuals\n",
    "lr = .1\n",
    "trees = []\n",
    "for i in range(20):\n",
    "    tree = DecisionTreeRegressor(max_depth=5) # init tree\n",
    "    tree.fit(train_data, train_target)        # fit tree to train data\n",
    "    preds = tree.predict(train_data)          # Get predictions\n",
    "    residuals = preds -  train_target         # Compute residuals\n",
    "    resi.append(np.sum(resi) + lr*residuals)  # Build regression tree to predict residuals\n",
    "    trees.append(tree)\n",
    "resi[0]= resi[0]/lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.477  , 0.458  , 5.00001, ..., 5.00001, 0.723  , 1.515  ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resi = []                                 # Array to keep track of residuals\n",
    "lr = .1\n",
    "trees = []\n",
    "tree = DecisionTreeRegressor(max_depth=5) # init tree\n",
    "tree.fit(train_data, train_target)        # fit tree to train data\n",
    "preds = tree.predict(train_data)          # Get predictions\n",
    "residuals = preds -  train_target         # Compute residuals\n",
    "resi.append(np.sum(resi) + lr*residuals)  # Build regression tree to predict residuals\n",
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLh-RSs7OiJT"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3330562514.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 18\u001b[0;36m\u001b[0m\n\u001b[0;31m    #YOUR CODE HERE\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class GradientBoostingRegressor():\n",
    "  def __init__(self,learning_rate, n_estimators, max_depth):\n",
    "    self.learning_rate = learning_rate\n",
    "    self.n_estimators = n_estimators\n",
    "    self.max_depth = max_depth\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    # self.trees = []\n",
    "    # for i in range(self.n_estimators):\n",
    "    #   cur_tree = DecisionTreeRegressor(max_depth=self.max_depth, random_state=42) \n",
    "    #   cur_tree.fit(X, y) # Fitting the tree to data and target (tree is built)\n",
    "    #   predictions = cur_tree.predict(y) # Getting predictions on the data\n",
    "    #   tree_mse = mse\n",
    "\n",
    "    #   self.trees.append(cur_tree)\n",
    "    residuals = []\n",
    "    first_tree = DecisionTreeRegressor(max_depth=5) # adding first residuals seperately\n",
    "    first_pred = first_tree.predict(X)\n",
    "    first_residual = y-first_pred\n",
    "    residuals[0] = first_residual\n",
    "    for i in range(1,self.n_estimators):\n",
    "      \n",
    "\n",
    "\n",
    "  def predict(self, X):\n",
    "    #YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkKW7G3uXmpA"
   },
   "source": [
    "Finally, fit a Gradient Boosted Tree regressor to the training data (use `learning_rate=0.5`, `n_estimators=20`, and `max_depth=5`) and compute its mean squared error on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQpbk_ElP40p"
   },
   "outputs": [],
   "source": [
    "GBT= GradientBoostingRegressor(learning_rate=0.5, n_estimators=20, max_depth=5)\n",
    "GBT.fit(test_data, test_target)\n",
    "pred = GBT.predict(test_data)\n",
    "GBT_mse= mse(test_target, pred) \n",
    "GBT_mse"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNCPbXfqFTbO1g2GYoZAY6L",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
