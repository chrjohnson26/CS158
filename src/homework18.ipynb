{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRhTLUOx2st_"
   },
   "source": [
    "**Homework 18**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MA2PT7gdJCeU"
   },
   "source": [
    "**IMPORTANT!!!** Complete this notebook to do your homework, and then transfer your answers to homework18gradescope.ipynb (available on canvas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yqXf1hfJZ9J"
   },
   "source": [
    "In this assignment we'll start working with PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 12195,
     "status": "ok",
     "timestamp": 1743528742394,
     "user": {
      "displayName": "David Bachman",
      "userId": "02952839939203243924"
     },
     "user_tz": 420
    },
    "id": "BNcIbf6Wk-mT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, ReLU, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3ONia8dlFcz"
   },
   "source": [
    "Let's use PyTorch to recreate the Neural Network from Homework 16:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1743528742453,
     "user": {
      "displayName": "David Bachman",
      "userId": "02952839939203243924"
     },
     "user_tz": 420
    },
    "id": "OOnzcgDKo7kc"
   },
   "outputs": [],
   "source": [
    "network=Sequential(\n",
    "    Linear(2,3),\n",
    "    ReLU(),\n",
    "    Linear(3,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEi92gkcJDBL"
   },
   "source": [
    "You should be able to use it the exact same way, except that we apply PyTorch models to PyTorch tensors, rather than Numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 153,
     "status": "ok",
     "timestamp": 1743528750936,
     "user": {
      "displayName": "David Bachman",
      "userId": "02952839939203243924"
     },
     "user_tz": 420
    },
    "id": "UHgnBu2x6fre",
    "outputId": "b5364563-cd25-4be9-95ab-10884d22850b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2880],\n",
       "        [-0.5882],\n",
       "        [-0.2275],\n",
       "        [-0.4799],\n",
       "        [-0.7011],\n",
       "        [-0.3055],\n",
       "        [-0.8219],\n",
       "        [-0.1546],\n",
       "        [-0.3654],\n",
       "        [-0.3562],\n",
       "        [-0.6293],\n",
       "        [-0.5050],\n",
       "        [-0.4836],\n",
       "        [-0.4556],\n",
       "        [-0.4569]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.randn(15,2) #generate a random feature matrix with 2 features and 15 observations as a torch tensor\n",
    "network(X) #Predictions of our network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jld0gvNsK9Rj"
   },
   "source": [
    "You can see the weights and biases of your network as follows. Note that the first layer has a weight matrix of shape (3,2) and a bias vector of size 3, and the second layer has a weight matrix of shape(1,3) and a single bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1743528791110,
     "user": {
      "displayName": "David Bachman",
      "userId": "02952839939203243924"
     },
     "user_tz": 420
    },
    "id": "7Tz6A2jGJa0u",
    "outputId": "eaf0df1f-a4e7-4cb0-cacb-5cd1b633d078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2574, -0.3060],\n",
      "        [ 0.0158,  0.6984],\n",
      "        [-0.3580,  0.0577]], requires_grad=True) torch.Size([3, 2])\n",
      "Parameter containing:\n",
      "tensor([-0.0503,  0.0749, -0.6119], requires_grad=True) torch.Size([3])\n",
      "Parameter containing:\n",
      "tensor([[ 0.3536, -0.2348,  0.4437]], requires_grad=True) torch.Size([1, 3])\n",
      "Parameter containing:\n",
      "tensor([-0.3654], requires_grad=True) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for param in network.parameters():\n",
    "    print(param,param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M1CdiZrLZ0z"
   },
   "source": [
    "We now use gradient descent to train our network. Let's create a target vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1743528835240,
     "user": {
      "displayName": "David Bachman",
      "userId": "02952839939203243924"
     },
     "user_tz": 420
    },
    "id": "e4F-ZacLLZJa"
   },
   "outputs": [],
   "source": [
    "target=torch.randn(15,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-oEApw3L6mA"
   },
   "source": [
    "Our training loop now follows the pattern from homework 17:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5574,
     "status": "ok",
     "timestamp": 1743528925814,
     "user": {
      "displayName": "David Bachman",
      "userId": "02952839939203243924"
     },
     "user_tz": 420
    },
    "id": "yRt4Z497L5-h",
    "outputId": "17e0636d-ce59-487f-cb4b-d3e22ec83606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0/10000, Loss: 1.2329928874969482\n",
      "Step: 1000/10000, Loss: 0.5991779565811157\n",
      "Step: 2000/10000, Loss: 0.5090927481651306\n",
      "Step: 3000/10000, Loss: 0.49895647168159485\n",
      "Step: 4000/10000, Loss: 0.4952594041824341\n",
      "Step: 5000/10000, Loss: 0.4950980842113495\n",
      "Step: 6000/10000, Loss: 0.4949895739555359\n",
      "Step: 7000/10000, Loss: 0.49499908089637756\n",
      "Step: 8000/10000, Loss: 0.4950370788574219\n",
      "Step: 9000/10000, Loss: 0.4950786828994751\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000): #Do 10000 gradient descent steps\n",
    "  network.zero_grad() #Zero out the derivative with respect to each network parameter\n",
    "\n",
    "  prediction=network(X) #Compute the network prediction\n",
    "  MSEloss=torch.nn.MSELoss()(prediction,target) #Compute MSE loss\n",
    "  #MSEloss=((prediction-target)**2).mean() #This is the same!!\n",
    "\n",
    "  MSEloss.backward() #Compute gradient\n",
    "\n",
    "  for param in network.parameters():\n",
    "    param.data-=0.01*param.grad  #Take a gradient descent step with learning rate of 0.01\n",
    "\n",
    "  if i%1000==0:\n",
    "    print(f\"Step: {i}/10000, Loss: {MSEloss.item()}\") #Periodic reporting to track progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POe8lSSLO3PW"
   },
   "source": [
    "Let's now use this on real data. We'll use the same three colunns from the `cars` dataset that we usd in Homework 7, and again use the `mpg` column for our target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EeCKsV_BNnN4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cars=pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/causaldata/auto.csv')\n",
    "\n",
    "DWG=torch.tensor([cars.displacement,cars.weight,cars.gear_ratio],dtype=torch.float32).T\n",
    "mpg=torch.tensor(cars.mpg,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1WpWNB3nmeq"
   },
   "source": [
    "Define a neural network appropriate for predicting `mpg` from `DWG`. Your network should have two hidden layers with 8 neurons and 4 neurons, and ReLU layers before and after all hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cmkOVrzhPOON"
   },
   "outputs": [],
   "source": [
    "cars_network=Sequential(\n",
    "    Linear(3,8),\n",
    "    ReLU(),\n",
    "    Linear(8,4),\n",
    "    ReLU(),\n",
    "    Linear(4,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5EUhSA1oAsE"
   },
   "source": [
    "Write a training loop to train your network to predict `mpg` from `DWG`. Do 10000 gradient descent steps with a learning rate of 0.001, and report your MSE every 10000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Nmg9LgC0Ppsv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0/10000, Loss: 33.019718170166016\n",
      "Step: 1000/10000, Loss: 33.019718170166016\n",
      "Step: 2000/10000, Loss: 33.019718170166016\n",
      "Step: 3000/10000, Loss: 33.019718170166016\n",
      "Step: 4000/10000, Loss: 33.019718170166016\n",
      "Step: 5000/10000, Loss: 33.019718170166016\n",
      "Step: 6000/10000, Loss: 33.019718170166016\n",
      "Step: 7000/10000, Loss: 33.019718170166016\n",
      "Step: 8000/10000, Loss: 33.019718170166016\n",
      "Step: 9000/10000, Loss: 33.019718170166016\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "report = 1000\n",
    "for i in range(10000):\n",
    "    cars_network.zero_grad()\n",
    "    preds = cars_network(DWG)\n",
    "    MSEloss = torch.nn.MSELoss()(preds,mpg)\n",
    "\n",
    "    MSEloss.backward()\n",
    "\n",
    "    for param in cars_network.parameters():\n",
    "        param.data-=lr*param.grad\n",
    "\n",
    "    if i%report == 0:\n",
    "        print(f\"Step: {i}/10000, Loss: {MSEloss.item()}\") #Periodic reporting to track progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smClA-i87tVD"
   },
   "source": [
    "Compute the final MSE for your trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9WOOB_4C7yxz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.019718170166016"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mse= torch.nn.MSELoss()(preds,mpg).item()\n",
    "final_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jsECXtc0wfZ"
   },
   "source": [
    "For classification problems, here are the only changes:\n",
    "1. If you are predicting $n$ classes, the final layer should have $n$ neurons.\n",
    "2. For training, use Categorical Cross Entropy loss (torch.nn.CrossEntropyLoss) instead of MSE. (No need to one-hot encode target variable)\n",
    "3. If you want to generate predictions of your model (to guage accuracy, for example), use: `torch.argmax(network(X), dim=1)`\n",
    "4. If you want to see the probability that your model predicts each class, use: `torch.softmax(network(X), dim=1)`.\n",
    "\n",
    "With these changes in mind, we'll revisit the iris dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "LvBbFS7BP6Zw"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris=load_iris()\n",
    "\n",
    "X=torch.tensor(iris.data, dtype=torch.float32)\n",
    "y=torch.tensor(iris.target, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgihWnR0434E"
   },
   "source": [
    "Create a neural network appropriate for predicting `y` from `X`, with one hidden layer that has 10 neurons, and ReLU layers before and after that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "kq0iKMpysLmr"
   },
   "outputs": [],
   "source": [
    "iris_net= Sequential(\n",
    "    Linear(4,10),\n",
    "    ReLU(),\n",
    "    Linear(10,3) # since there are 3 possible classes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDIXXZUG5go8"
   },
   "source": [
    "Train your neural network for 10000 steps, with a learning rate of 0.01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1ST3a8XasqPl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0/10000, Loss: 1.3079663515090942\n",
      "Step: 1000/10000, Loss: 0.20890191197395325\n",
      "Step: 2000/10000, Loss: 0.1133594661951065\n",
      "Step: 3000/10000, Loss: 0.0874786451458931\n",
      "Step: 4000/10000, Loss: 0.07644724100828171\n",
      "Step: 5000/10000, Loss: 0.07041984796524048\n",
      "Step: 6000/10000, Loss: 0.06660681962966919\n",
      "Step: 7000/10000, Loss: 0.06394850462675095\n",
      "Step: 8000/10000, Loss: 0.06196235120296478\n",
      "Step: 9000/10000, Loss: 0.060401078313589096\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "for i in range(10000):\n",
    "    iris_net.zero_grad()\n",
    "    preds = iris_net(X)\n",
    "    CCEloss = torch.nn.CrossEntropyLoss()(preds,y)\n",
    "\n",
    "    CCEloss.backward()\n",
    "\n",
    "    for param in iris_net.parameters():\n",
    "        param.data -= lr*param.grad\n",
    "\n",
    "    if i%1000==0:\n",
    "        print(f\"Step: {i}/10000, Loss: {CCEloss.item()}\") #Periodic reporting to track progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AcwZO1D7DPa"
   },
   "source": [
    "What is the probability that your model assigns to flower 133 being in class 1? class 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.softmax(iris_net(X), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32666666666666666"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = torch.argmax(probs,axis=1)\n",
    "preds[preds == 1].shape[0]/preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "aWjqVCzm6DM2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3333333333333333, 0.32666666666666666)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1_prob= preds[preds == 0].shape[0]/preds.shape[0]\n",
    "class2_prob=preds[preds == 1].shape[0]/preds.shape[0]\n",
    "class1_prob,class2_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thU6rJLS7WHI"
   },
   "source": [
    "Create a vector of predictions for your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "OOwvw87X2gAh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions= preds\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWuL34Yc7cXa"
   },
   "source": [
    "Compute the accuracy of your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "OsaQnKJTt2tL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9800)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy= (preds ==y).sum()/150\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1RykR9AWdIvmZXusY8IFVw_Z8to1L-Uf_",
     "timestamp": 1648433498372
    }
   ]
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
