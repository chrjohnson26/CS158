{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGhBELjhF4PM"
   },
   "source": [
    "**Homework 21**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FL1p_4sFWAmy"
   },
   "source": [
    "In this assignment you will create a Convolutional Neural Network to do facial recognition. We begin by importing the dataset of face photos from the previous assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "S-AVC0Qq4uJb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchinfo\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "faces=lfw_people.images\n",
    "names=lfw_people.target_names\n",
    "target=lfw_people.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzw58xkavdsA"
   },
   "source": [
    "We start with an 80/20 train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "PYSHbEWUY_39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 50, 37)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces_train, faces_test, target_train, target_test=train_test_split(faces,target,train_size=0.8)\n",
    "faces_train.shape\n",
    "# target_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6URwmKjPF9Ry"
   },
   "source": [
    "\n",
    "Here are the imports that you will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "rCt1qlA2E1At"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G25yvqdtYdZe"
   },
   "source": [
    "The faces dataset is already scaled appropriately, so we can skip that step. Next, we convert the training and testing targets to pytorch tensors and modify their shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "mfL8X5EH9LRq"
   },
   "outputs": [],
   "source": [
    "faces_train=torch.tensor(faces_train).float().reshape(-1,1,50,37)\n",
    "faces_test=torch.tensor(faces_test).float().reshape(-1,1,50,37)\n",
    "target_train=torch.tensor(target_train)\n",
    "target_test=torch.tensor(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(faces_train[11],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 37])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces_train[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kyT-Jg1xLiy"
   },
   "source": [
    "Create a CNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "FmALBder8Y67"
   },
   "outputs": [],
   "source": [
    "# Greyscale so 1 input channel\n",
    "\n",
    "model=nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=(3,3), padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(16, 32, kernel_size=(3,3), padding =1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(32,64, kernel_size=(3,3), padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(1536, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(64,7)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1030, 7])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(faces_train).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-suOCW-Vyur-"
   },
   "source": [
    "Define an Adam optimizer for this model with an initial learning rate of 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for par in model.parameters():\n",
    "#     print(par.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "3l5Q5E148ulV"
   },
   "outputs": [],
   "source": [
    "optimizer= Adam(model.parameters(), 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZunlBYkgy9YA"
   },
   "source": [
    "Defie a training loop to fit your model faces_train and y_train. Train for 20 epochs in batches of size 32. Every other epoch report the accuracy of the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3OGZTBLu80AR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.7769851684570312\n",
      "epoch: 10, loss: 0.19902397692203522\n",
      "epoch: 20, loss: 0.2995610237121582\n",
      "epoch: 30, loss: 0.005390379577875137\n",
      "epoch: 40, loss: 0.045512855052948\n",
      "epoch: 50, loss: 0.4724731147289276\n",
      "epoch: 60, loss: 0.6835537552833557\n",
      "epoch: 70, loss: 0.3021252751350403\n",
      "epoch: 80, loss: 0.0\n",
      "epoch: 90, loss: 0.4300449788570404\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "n_epochs=100\n",
    "N = faces_train.shape[0]  # total number of observations in training data\n",
    "batch_size=32\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  model.train()\n",
    "  # Shuffle the indices\n",
    "  indices = torch.randperm(N)\n",
    "\n",
    "  # Create mini-batches\n",
    "  for i in range(0, N, batch_size):\n",
    "    batch_indices = indices[i:i+batch_size]\n",
    "    batch_X = faces_train[batch_indices]\n",
    "    batch_y = target_train[batch_indices]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(batch_X)\n",
    "\n",
    "    CELoss = torch.nn.CrossEntropyLoss()(predictions, batch_y)\n",
    "\n",
    "    CELoss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  if epoch%10==0:\n",
    "    print(f\"epoch: {epoch}, loss: {CELoss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9534883499145508\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred= model(faces_test)  # -- generate predictions for the test set.\n",
    "    # accuracy= ((y_pred == target_test).sum / target_test.shape[0]) * 100\n",
    "accuracy = (y_pred.argmax(dim=1) == target_test).float().mean().item()\n",
    "# print(f\"epoch: {epoch}, accuracy: {accuracy}\")\n",
    "print(f\"accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Sp9yub6zGZv"
   },
   "source": [
    "Transfer your final accuracy to the file \"heomwork21gradescope.py\"."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNueIVLrM0lH7/dYkWdjb/C",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
